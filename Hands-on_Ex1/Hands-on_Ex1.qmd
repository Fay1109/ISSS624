---
title: "Hands-on Exercise 1: Geospatial Data Wrangling with R"
editor: visual
---

## Overview

In this hands-on exercise, I learn how to import and wrangling geospatial data using appropriate R packages.

## Getting Started

The code chunk below install and load [sf](https://r-spatial.github.io/sf/) and tidyverse packages into R environment.

```{r}
pacman::p_load(sf,tidyverse)
```

## Importing Geospatial Data

### Importing polygon feature data

```{r}
mpsz <- st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

### Importing polyline feature data in shapefile form

```{r}
cyclingpath = st_read(dsn = "data/geospatial", layer = "CyclingPath")
```

### Importing GIS data in kml format

```{r}
preschool = st_read("data/geospatial/pre-schools-location-kml.kml")
```

## Checking the Content of A Simple Feature Data Frame

### Working with *st_geometry()*

```{r}
st_geometry(mpsz)
```

### Working with glimpse()

```{r}
library(dplyr)
glimpse(mpsz)
```

### Working with *head()*

```{r}
head(mpsz, n=5)  
```

## Plotting the Geospatial Data

```{r}
plot(mpsz)
```

```{r}
plot(st_geometry(mpsz))
```

```{r}
plot(mpsz["PLN_AREA_N"])
```

## Working with Projection

### Assigning EPSG code to a simple feature data frame

```{r}
st_crs(mpsz)
```

```{r}
mpsz3414 <- st_set_crs(mpsz, 3414)
```

```{r}
st_crs(mpsz3414)
```

### Transforming the projection of preschool from wgs84 to svy21.

```{r}
preschool3414 <- st_transform(preschool, crs = 3414)
```

## Importing and Converting An Aspatial Data

### Importing the aspatial data

```{r}
library(readr)
listings <- read_csv("data/aspatial/listings.csv")
```

```{r}
list(listings) 
```

### Creating a simple feature data frame from an aspatial data frame

```{r}
listings_sf <- st_as_sf(listings, 
                       coords = c("longitude", "latitude"),
                       crs=4326) %>%
  st_transform(crs = 3414)
```

```{r}
glimpse(listings_sf)
```

## Geoprocessing with sf package

### Buffering

```{r}
buffer_cycling <- st_buffer(cyclingpath, 
                               dist=5, nQuadSegs = 30)
```

```{r}
buffer_cycling$AREA <- st_area(buffer_cycling)
```

```{r}
sum(buffer_cycling$AREA)
```

### Point-in-polygon count

```{r}
mpsz3414$`PreSch Count`<- lengths(st_intersects(mpsz3414, preschool3414))
```

```{r}
summary(mpsz3414$`PreSch Count`)
```

```{r}
top_n(mpsz3414, 1, `PreSch Count`)
```

```{r}
mpsz3414$Area <- mpsz3414 %>%
  st_area()
```

```{r}
mpsz3414 <- mpsz3414 %>%
  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)
```

## Explorotary Data Analysis (EDA)

```{r}
hist(mpsz3414$`PreSch Density`)
```

```{r}
library(ggplot2)
ggplot(data=mpsz3414, 
       aes(x= as.numeric(`PreSch Density`)))+
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  labs(title = "Are pre-school even distributed in Singapore?",
       subtitle= "There are many planning sub-zones with a single pre-school, on the other hand, \nthere are two planning sub-zones with at least 20 pre-schools",
      x = "Pre-school density (per km sq)",
      y = "Frequency")
```

```{r}
ggplot(data=mpsz3414,

aes(x= as.numeric(`PreSch Density`), y= as.numeric(`PreSch Count`)))+

geom_point() +

labs(title = "Are pre-school even distributed in Singapore?",

subtitle= "There are many planning sub-zones with a single pre-school, on the other hand, \nthere are two planning sub-zones with at least 20 pre-schools",

x = "Pre-school density (per km sq)",

y = "Pre-school Count")
```

# Choropleth Mapping with R

## Overview

In this chapter, I will learn how to plot functional and truthful choropleth maps by using an R package called \*\*tmap\*\* package.

### Survival Tip

It is advisable for you to read the functional description of each function before using them.

## Getting Started

In this hands-on exercise, the key R package use is [**tmap**](https://cran.r-project.org/web/packages/tmap/) package in R. Beside **tmap** package, four other R packages will be used. They are:

-   [**readr**](https://readr.tidyverse.org/) for importing delimited text file,

-   [**tidyr**](https://tidyr.tidyverse.org/) for tidying data,

-   [**dplyr**](https://dplyr.tidyverse.org/) for wrangling data and

-   [**sf**](https://cran.r-project.org/web/packages/sf/) for handling geospatial data.

The code chunk below will be used to install and load these packages in RStudio.

```{r}
pacman::p_load(sf, tmap, tidyverse)
```

## Importing Data into R

### The Data

### Importing Geospatial Data into R

```{r}
mpsz <- st_read(dsn = "data/geospatial", 
                layer = "MP14_SUBZONE_WEB_PL")
```

```{r}
mpsz
```

### Importing Attribute Data into R

```{r}
popdata <- read_csv("data/aspatial/respopagesextod2011to2020.csv")
```

### Data Preparation

#### Data wrangling

```{r}
popdata2020 <- popdata %>%
  filter(Time == 2020) %>%
  group_by(PA, SZ, AG) %>%
  summarise(`POP` = sum(`Pop`)) %>%
  ungroup()%>%
  pivot_wider(names_from=AG, 
              values_from=POP) %>%
  mutate(YOUNG = rowSums(.[3:6])
         +rowSums(.[12])) %>%
mutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+
rowSums(.[13:15]))%>%
mutate(`AGED`=rowSums(.[16:21])) %>%
mutate(`TOTAL`=rowSums(.[3:21])) %>%  
mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)
/`ECONOMY ACTIVE`) %>%
  select(`PA`, `SZ`, `YOUNG`, 
       `ECONOMY ACTIVE`, `AGED`, 
       `TOTAL`, `DEPENDENCY`)
```

#### Joining the attribute data and geospatial data

```{r}
popdata2020 <- popdata2020 %>%
  mutate_at(.vars = vars(PA, SZ), 
          .funs = funs(toupper)) %>%
  filter(`ECONOMY ACTIVE` > 0)
```

```{r}
mpsz_pop2020 <- left_join(mpsz, popdata2020,
                          by = c("SUBZONE_N" = "SZ"))
```

```{r}
write_rds(mpsz_pop2020, "data/rds/mpszpop2020.rds")
```

## Choropleth Mapping Geospatial Data Using *tmap*

### Plotting a choropleth map quickly by using *qtm()*

```{r}
tmap_mode("plot")
qtm(mpsz_pop2020, 
    fill = "DEPENDENCY")
```

### Creating a choropleth map by using *tmap*'s elements

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY", 
          style = "quantile", 
          palette = "Blues",
          title = "Dependency ratio") +
  tm_layout(main.title = "Distribution of Dependency Ratio by planning subzone",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\n and Population data from Department of Statistics DOS", 
             position = c("left", "bottom"))
```

#### Drawing a base map

```{r}
tm_shape(mpsz_pop2020) +
  tm_polygons()
```

#### Drawing a choropleth map using *tm_polygons()*

```{r}
tm_shape(mpsz_pop2020)+
  tm_polygons("DEPENDENCY")
```

#### Drawing a choropleth map using *tm_fill()* and \*tm_border()\*\*

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY")
```

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY") +
  tm_borders(lwd = 0.1,  alpha = 1)
```

### Data classification methods of **tmap**

#### Plotting choropleth maps with built-in classification methods

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5)
```

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5)
```

#### Plotting choropleth map with custome break

```{r}
summary(mpsz_pop2020$DEPENDENCY)
```

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +
  tm_borders(alpha = 0.5)
```

### Colour Scheme

#### Using ColourBrewer palette

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          n = 6,
          style = "quantile",
          palette = "Blues") +
  tm_borders(alpha = 0.5)
```

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          style = "quantile",
          palette = "-Greens") +
  tm_borders(alpha = 0.5)
```

### Map Layouts

#### Map Legend

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY", 
          style = "jenks", 
          palette = "Blues", 
          legend.hist = TRUE, 
          legend.is.portrait = TRUE,
          legend.hist.z = 0.1) +
  tm_layout(main.title = "Distribution of Dependency Ratio by planning subzone \n(Jenks classification)",
            main.title.position = "center",
            main.title.size = 1,
            legend.height = 0.45, 
            legend.width = 0.35,
            legend.outside = FALSE,
            legend.position = c("right", "bottom"),
            frame = FALSE) +
  tm_borders(alpha = 0.5)
```

#### Map style

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY", 
          style = "quantile", 
          palette = "-Greens") +
  tm_borders(alpha = 0.5) +
  tmap_style("classic")
```

#### Cartographic Furniture

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY", 
          style = "quantile", 
          palette = "Blues",
          title = "No. of persons") +
  tm_layout(main.title = "Distribution of Dependency Ratio \nby planning subzone",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar(width = 0.15) +
  tm_grid(lwd = 0.1, alpha = 0.2) +
  tm_credits("Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\n and Population data from Department of Statistics DOS", 
             position = c("left", "bottom"))
```

```{r}
tmap_style("white")
```

### Drawing Small Multiple Choropleth Maps

#### By assigning multiple values to at least one of the aesthetic arguments

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill(c("YOUNG", "AGED"),
          style = "equal", 
          palette = "Blues") +
  tm_layout(legend.position = c("right", "bottom")) +
  tm_borders(alpha = 0.5) +
  tmap_style("white")
```

```{r}
tm_shape(mpsz_pop2020)+ 
  tm_polygons(c("DEPENDENCY","AGED"),
          style = c("equal", "quantile"), 
          palette = list("Blues","Greens")) +
  tm_layout(legend.position = c("right", "bottom"))
```

#### By defining a group-by variable in *tm_facets()*

```{r}
tm_shape(mpsz_pop2020) +
  tm_fill("DEPENDENCY",
          style = "quantile",
          palette = "Blues",
          thres.poly = 0) + 
  tm_facets(by="REGION_N", 
            free.coords=TRUE, 
            drop.shapes=TRUE) +
  tm_layout(legend.show = FALSE,
            title.position = c("center", "center"), 
            title.size = 20) +
  tm_borders(alpha = 0.5)
```

#### By creating multiple stand-alone maps with *tmap_arrange()*

```{r}
youngmap <- tm_shape(mpsz_pop2020)+ 
  tm_polygons("YOUNG", 
              style = "quantile", 
              palette = "Blues")

agedmap <- tm_shape(mpsz_pop2020)+ 
  tm_polygons("AGED", 
              style = "quantile", 
              palette = "Blues")

tmap_arrange(youngmap, agedmap, asp=1, ncol=2)
```

### Mappping Spatial Object Meeting a Selection Criterion

```{r}
tm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N=="CENTRAL REGION", ])+
  tm_fill("DEPENDENCY", 
          style = "quantile", 
          palette = "Blues", 
          legend.hist = TRUE, 
          legend.is.portrait = TRUE,
          legend.hist.z = 0.1) +
  tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE) +
  tm_borders(alpha = 0.5)
```

## Reference

### All about **tmap** package

-   [tmap: Thematic Maps in R](https://www.jstatsoft.org/article/view/v084i06)

-   [tmap](https://cran.r-project.org/web/packages/tmap/)

-   [tmap: get started!](https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html)

-   [tmap: changes in version 2.0](https://cran.r-project.org/web/packages/tmap/vignettes/tmap-changes-v2.html)

-   [tmap: creating thematic maps in a flexible way (useR!2015)](http://von-tijn.nl/tijn/research/presentations/tmap_user2015.pdf)

-   [Exploring and presenting maps with tmap (useR!2017)](http://von-tijn.nl/tijn/research/presentations/tmap_user2017.pdf)

### Geospatial data wrangling

-   [sf: Simple Features for R](https://cran.r-project.org/web/packages/sf/)

-   [Simple Features for R: StandardizedSupport for Spatial Vector Data](https://journal.r-project.org/archive/2018/RJ-2018-009/RJ-2018-009.pdf)

-   [Reading, Writing and Converting Simple Features](https://cran.r-project.org/web/packages/sf/vignettes/sf2.html)

### Data wrangling

-   [dplyr](https://dplyr.tidyverse.org/)

-   [Tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html)

-   [tidyr: Easily Tidy Data with 'spread()' and 'gather()' Functions](https://cran.r-project.org/web/packages/tidyr/tidyr.pdf)

# Spatial Weights and Applications

## Overview

## The Study Area and Data

Two data sets will be used in this hands-on exercise, they are:

-   Hunan county boundary layer. This is a geospatial data set in ESRI shapefile format.

-   Hunan_2012.csv: This csv file contains selected Hunan's local development indicators in 2012.

### Getting Started

Before we get started, we need to ensure that **spdep**, **sf**, **tmap** and **tidyverse** packages of R are currently installed in your R.

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse)
```

## Getting the Data Into R Environment

In this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.

### Import shapefile into r environment

The code chunk below uses [*st_read()*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import Hunan shapefile into R. The imported shapefile will be **simple features** Object of **sf**.

```{r}
hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```

    Import csv file into r environment
    Next, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

    Performing relational join
    The code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.

```{r}
hunan <- left_join(hunan,hunan2012)
```

    Visualising Regional Development Indicator
    Now, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.

```{r}
basemap <- tm_shape(hunan) +
  tm_polygons() +
  tm_text("NAME_3", size=0.5)

gdppc <- qtm(hunan, "GDPPC")
tmap_arrange(basemap, gdppc, asp=1, ncol=2)
```

    Computing Contiguity Spatial Weights
    In this section, you will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.

    Computing (QUEEN) contiguity based neighbours
    The code chunk below is used to compute Queen contiguity weight matrix.

```{r}
wm_q <- poly2nb(hunan, queen=TRUE)
summary(wm_q)
```

    The summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.

    For each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:

```{r}
wm_q[[1]]
```

```{r}
hunan$County[1]
```

```{r}
hunan$NAME_3[c(2,3,4,57,85)]
```

```{r}
nb1 <- wm_q[[1]]
nb1 <- hunan$GDPPC[nb1]
nb1
```

```{r}
str(wm_q)
```

### Creating (ROOK) contiguity based neighbours

The code chunk below is used to compute Rook contiguity weight matrix.

```{r}
wm_r <- poly2nb(hunan, queen=FALSE)
summary(wm_r)
```

### Visualising contiguity weights

A connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids

We will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation

To get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation \[\[\]\] and 1. This allows us to get only the longitude, which is the first value in each centroid.

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

We do the same for latitude with one key difference. We access the second value per each centroid with \[\[2\]\].

```{r}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

Now that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.

```{r}
coords <- cbind(longitude, latitude)
```

```{r}
head(coords)
```

#### Plotting Queen contiguity based neighbours map

```{r}
plot(hunan$geometry, border="lightgrey")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= "red")
```

#### Plotting Rook contiguity based neighbours map

```{r}
plot(hunan$geometry, border="lightgrey")
plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

#### Plotting both Queen and Rook contiguity based neighbours maps

```{r}
par(mfrow=c(1,2))
plot(hunan$geometry, border="lightgrey")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= "red", main="Queen Contiguity")
plot(hunan$geometry, border="lightgrey")
plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = "red", main="Rook Contiguity")
```

## Computing distance based neighbours

In this section, you will learn how to derive distance-based weight matrices by using [*dnearneigh()*](https://r-spatial.github.io/spdep/reference/dnearneigh.html) of **spdep** package.

The function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in **km** will be calculated assuming the WGS84 reference ellipsoid.

### Determine the cut-off distance

Firstly, we need to determine the upper limit for distance band by using the steps below:

-   Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using [*knearneigh()*](https://r-spatial.github.io/spdep/reference/knearneigh.html) of **spdep**.

-   Convert the knn object returned by *knearneigh()* into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using [*knn2nb()*](https://r-spatial.github.io/spdep/reference/knn2nb.html).

-   Return the length of neighbour relationship edges by using [*nbdists()*](https://r-spatial.github.io/spdep/reference/nbdists.html) of **spdep**. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.

-   Remove the list structure of the returned object by using [**unlist()**](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unlist).

```{r}
#coords <- coordinates(hunan)
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.

### Computing fixed distance weight matrix

Now, we will compute the distance weight matrix by using *dnearneigh()* as shown in the code chunk below.

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

Next, we will use *str()* to display the content of wm_d62 weight matrix.

```{r}
str(wm_d62)
```

```{r}
table(hunan$County, card(wm_d62))
```

```{r}
n_comp <- n.comp.nb(wm_d62)
n_comp$nc
```

```{r}
table(n_comp$comp.id)
```

#### Plotting fixed distance weight matrix

Next, we will plot the distance weight matrix by using the code chunk below.

```{r}
plot(hunan$geometry, border="lightgrey")
plot(wm_d62, coords, add=TRUE)
plot(k1, coords, add=TRUE, col="red", length=0.08)
```

The red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.

Alternatively, we can plot both of them next to each other by using the code chunk below.

```{r}
par(mfrow=c(1,2))
plot(hunan$geometry, border="lightgrey")
plot(k1, coords, add=TRUE, col="red", length=0.08, main="1st nearest neighbours")
plot(hunan$geometry, border="lightgrey")
plot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6, main="Distance link")
```

### Computing adaptive distance weight matrix

One of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.

It is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.

```{r}
knn6 <- knn2nb(knearneigh(coords, k=6))
knn6
```

```{r}
str(knn6)
```

#### Plotting distance based neighbours

We can plot the weight matrix using the code chunk below.

```{r}
plot(hunan$geometry, border="lightgrey")
plot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

## Weights based on IDW

In this section, you will learn how to derive a spatial weight matrix based on Inversed Distance method.

First, we will compute the distances between areas by using [*nbdists()*](https://r-spatial.github.io/spdep/reference/nbdists.html) of **spdep**.

```{r}
dist <- nbdists(wm_q, coords, longlat = TRUE)
ids <- lapply(dist, function(x) 1/(x))
ids
```

### Row-standardised weights matrix

Next, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style="W"). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors' values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we'll stick with the style="W" option for simplicity's sake but note that other more robust options are available, notably style="B".

```{r}
rswm_q <- nb2listw(wm_q, style="W", zero.policy = TRUE)
rswm_q
```

The zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.

To see the weight of the first polygon's four neighbors type:

```{r}
rswm_q$weights[10]
```

Each neighbor is assigned a 0.2 of the total weight. This means that when R computes the average neighboring income values, each neighbor's income will be multiplied by 0.2 before being tallied.

Using the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.

```{r}
rswm_ids <- nb2listw(wm_q, glist=ids, style="B", zero.policy=TRUE)
rswm_ids
```

```{r}
rswm_ids$weights[1]
```

```{r}
summary(unlist(rswm_ids$weights))
```

## Application of Spatial Weight Matrix

In this section, you will learn how to create four different spatial lagged variables, they are:

-   spatial lag with row-standardized weights,

-   spatial lag as a sum of neighbouring values,

-   spatial window average, and spatial window sum.

### Spatial lag with row-standardized weights

Finally, we'll compute the average neighbor GDPPC value for each polygon. These values are often referred to as **spatially lagged values**.

```{r}
GDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)
GDPPC.lag
```

Recalled in the previous section, we retrieved the GDPPC of these five countries by using the code chunk below.

```{r}
nb1 <- wm_q[[1]]
nb1 <- hunan$GDPPC[nb1]
nb1
```

We can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.

```{r}
lag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))
lag.res <- as.data.frame(lag.list)
colnames(lag.res) <- c("NAME_3", "lag GDPPC")
hunan <- left_join(hunan,lag.res)
```

The following table shows the average neighboring income values (stored in the Inc.lag object) for each county.

```{r}
head(hunan)
```

Next, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.

```{r}
gdppc <- qtm(hunan, "GDPPC")
lag_gdppc <- qtm(hunan, "lag GDPPC")
tmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)
```

### Spatial lag as a sum of neighboring values

We can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.

We start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.

```{r}
b_weights <- lapply(wm_q, function(x) 0*x + 1)
b_weights2 <- nb2listw(wm_q, 
                       glist = b_weights, 
                       style = "B")
b_weights2
```

With the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.

```{r}
lag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))
lag.res <- as.data.frame(lag_sum)
colnames(lag.res) <- c("NAME_3", "lag_sum GDPPC")
```

First, let us examine the result by using the code chunk below.

```{r}
lag_sum
```

Next, we will append the *lag_sum GDPPC* field into `hunan` sf data frame by using the code chunk below.

```{r}
hunan <- left_join(hunan, lag.res)
```

Now, We can plot both the *GDPPC* and *Spatial Lag Sum GDPPC* for comparison using the code chunk below.

```{r}
gdppc <- qtm(hunan, "GDPPC")
lag_sum_gdppc <- qtm(hunan, "lag_sum GDPPC")
tmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)
```

### Spatial window average

The spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights. To begin we assign k6 to a new variable because we will directly alter its structure to add the diagonal elements.

```{r}
wm_q1 <- wm_q
```

To add the diagonal element to the neighbour list, we just need to use *include.self()* from **spdep**.

```{r}
include.self(wm_q1)
```

Now we obtain weights with *nb2listw()*

```{r}
wm_q1 <- nb2listw(wm_q1)
wm_q1
```

```{r}
lag_w_avg_gpdpc <- lag.listw(wm_q1, 
                             hunan$GDPPC)
lag_w_avg_gpdpc
```

```{r}
lag.list.wm_q1 <- list(hunan$NAME_3, lag.listw(wm_q1, hunan$GDPPC))
lag_wm_q1.res <- as.data.frame(lag.list.wm_q1)
colnames(lag_wm_q1.res) <- c("NAME_3", "lag_window_avg GDPPC")
```

Note: The third command line on the code chunk above renames the field names of *lag_wm_q1.res* object into *NAME_3* and *lag_window_avg GDPPC* respectively.

Next, the code chunk below will be used to append *lag_window_avg GDPPC* values onto *hunan* sf data.frame by using *left_join()* of **dplyr** package.

```{r}
hunan <- left_join(hunan, lag_wm_q1.res)
```

Lastly, *qtm()* of **tmap** package is used to plot the GDPPC and lag_window_avg GDPPC map next to each other for quick comparison.

```{r}
gdppc <- qtm(hunan, "GDPPC")
w_avg_gdppc <- qtm(hunan, "lag_window_avg GDPPC")
tmap_arrange(gdppc, w_avg_gdppc, asp=1, ncol=2)
```

### Spatial window sum

The spatial window sum is the counter part of the window average, but without using row-standardized weights. To do this we assign binary weights to the neighbor structure that includes the diagonal element.

```{r}
wm_q1 <- wm_q
```

```{r}
wm_q1
```

Next, we will assign binary weights to the neighbour structure that includes the diagonal element.

```{r}
b_weights <- lapply(wm_q1, function(x) 0*x + 1)
b_weights[1]
```

Again, we use *nb2listw()* and *glist()* to explicitly assign weight values.

```{r}
b_weights2 <- nb2listw(wm_q1, 
                       glist = b_weights, 
                       style = "B")
b_weights2
```

With our new weight structure, we can compute the lag variable with *lag.listw()*.

```{r}
w_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))
w_sum_gdppc
```

Next, we will convert the lag variable listw object into a data.frame by using *as.data.frame()*.

```{r}
w_sum_gdppc.res <- as.data.frame(w_sum_gdppc)
colnames(w_sum_gdppc.res) <- c("NAME_3", "w_sum GDPPC")
```

Note: The second command line on the code chunk above renames the field names of *w_sum_gdppc.res* object into *NAME_3* and *w_sum GDPPC* respectively.

Next, the code chunk below will be used to append *w_sum GDPPC* values onto *hunan* sf data.frame by using *left_join()* of **dplyr** package.

```{r}
hunan <- left_join(hunan, w_sum_gdppc.res)
```

Lastly, *qtm()* of **tmap** package is used to plot the GDPPC and lag_sum GDPPC map next to each other for quick comparison.

```{r}
gdppc <- qtm(hunan, "GDPPC")
w_sum_gdppc <- qtm(hunan, "w_sum GDPPC")
tmap_arrange(gdppc, w_sum_gdppc, asp=1, ncol=2)
```

## References

[Creating Neighbours using sf objects](https://cran.r-project.org/web/packages/spdep/vignettes/nb_sf.html)

## 
